{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mQDo5aC51Ek"
      },
      "outputs": [],
      "source": [
        "def summation_unit(inputs, weights):\n",
        "\n",
        "\n",
        "    if len(inputs) != len(weights):\n",
        "        raise ValueError(\"Inputs and weights must have the same length.\")\n",
        "    return sum(i * w for i, w in zip(inputs, weights))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def step_function(x):\n",
        "\n",
        "    #Step activation function.\n",
        "\n",
        "\n",
        "\n",
        "    return 1 if x >= 0 else 0\n"
      ],
      "metadata": {
        "id": "ZqfJwINE_qye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bipolar_step_function(x):\n",
        "\n",
        "    return 1 if x >= 0 else -1\n"
      ],
      "metadata": {
        "id": "tVP0VhMh_5N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "\n",
        "    return 1 / (1 + np.exp(-x))\n"
      ],
      "metadata": {
        "id": "YPI7sLHg_8ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    \"\"\"\n",
        "    Hyperbolic tangent activation function.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    return np.tanh(x)\n"
      ],
      "metadata": {
        "id": "MXO3WPayAY_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    \"\"\"\n",
        "    Rectified Linear Unit (ReLU) activation function.\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    return np.maximum(0, x)\n"
      ],
      "metadata": {
        "id": "sK5eK4ZZAd0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leaky_relu(x, alpha=0.01):\n",
        "    \"\"\"\n",
        "    Leaky Rectified Linear Unit (Leaky ReLU) activation function.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    return np.where(x > 0, x, alpha * x)\n"
      ],
      "metadata": {
        "id": "uKZ8tD5kAiTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Mean Squared Error (MSE) between true and predicted values.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean((y_true - y_pred) ** 2)\n"
      ],
      "metadata": {
        "id": "FWM6RgVpAmRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}